{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from boruta import BorutaPy \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_score(ypred,y):\n",
    "    tp=np.sum((ypred==1) & (y==1))\n",
    "   # print(\"tp\")\n",
    "    totmal=np.sum(y==1)\n",
    "   # print(tp)\n",
    "    #print(\"sum ypred:\")\n",
    "    #print(sum(ypred==1))\n",
    "    #print(\"sum y:\")\n",
    "    #print(sum(y==1))\n",
    "    #print(\"totmal\")\n",
    "    \n",
    "    #Non mi ritrovo nel dividere tutto per \"ypred.shape[0]\" la sensibilità è TruePos/totmalati\n",
    "    \n",
    "    #print(totpos)\n",
    "    print(tp/totmal)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione per calcolare F_score (o almeno dovrebbe) TruePos/(TruePos+ 1/2 (FalsePos+FalseNeg)) \n",
    "def f_score(ypred, y):\n",
    "    tp=np.sum((ypred==1) & (y==1))\n",
    "    fp=np.sum(ypred==1)-tp\n",
    "    tn=np.sum((ypred==0) & (y==0))\n",
    "    fn=np.sum(ypred==0)-tn\n",
    "    \n",
    "    print(tp/(tp+0.5*(fp+fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Funzione per calcolare la specificità (o almeno dovrebbe) TrueNeg/TotSani\n",
    "\n",
    "def specificity_score(ypred,y):\n",
    "    tn=np.sum((ypred==0) & (y==0))\n",
    "    totsani=np.sum(y==0)\n",
    "    \n",
    "    print (tn/totsani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 42)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "#carico il dataset\n",
    "data = pd.read_csv(r'C:\\Users\\Utente\\anaconda3\\Lib\\site-packages\\pandas\\io\\data_covnet_score-imputed_missRF_increasing_1.txt')\n",
    "print(data.shape)\n",
    "nit=15\n",
    "\n",
    "#il comando sotto non mi serve: Converte i dati categorici in dati classificabili.\n",
    "#data = pd.get_dummies(data, drop_first=True, dummy_na=True)\n",
    "#print(data.shape)\n",
    "\n",
    "y=data['LABEL']\n",
    "y=y.to_numpy()\n",
    "\n",
    "parzial_features = list()\n",
    "\n",
    "altri=data\n",
    "altri=altri.to_numpy()\n",
    "\n",
    "\n",
    "features = [f for f in data.columns if f not in ['LABEL']]\n",
    "#print(len(features))\n",
    "\n",
    "X = data[features].values\n",
    "\n",
    "#ravel() mi fa diventare l'array monodimensionale.\n",
    "Y = data['LABEL'].values.ravel()\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 100, max_depth=11, max_features=None, max_samples=0.75,class_weight=\"balanced\")\n",
    "\n",
    "\n",
    "o=0\n",
    "\n",
    "#creo un array monodimensionale lungo quanto \"altri\" ma solo di 0. \n",
    "y_pred=y-y\n",
    "n_fold=10\n",
    "\n",
    "#crea un oggetto pronto ad operare: quando gli arriva in input qualcosa lo divide in 10 pezzettini con la stessa proporzione\n",
    "skf = StratifiedKFold(n_splits=n_fold)\n",
    "\n",
    "\n",
    "for niter in range(nit):\n",
    "\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "            boruta_feature_selector = BorutaPy(rf, n_estimators='auto', verbose=0, max_iter = 50, perc = 40)\n",
    "\n",
    "            X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "            #usa boruta per selezionare le features più disciriminative dal training set\n",
    "            #prendi solo le features più significative sia nel training set che nel test set\n",
    "            y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "            boruta_feature_selector.fit(X_train, y_train)\n",
    "            indexes = np.where(boruta_feature_selector.support_ == True)\n",
    "            \n",
    "            \n",
    "            X_train_selected=boruta_feature_selector.transform(X_train)\n",
    "            X_test_selected=boruta_feature_selector.transform(X_test)\n",
    "            o=o+1\n",
    "            print(o)\n",
    "            #print(head(X_train_selected))\n",
    "            clf = rf.fit(X_train_selected, y_train)\n",
    "           \n",
    "            y_pred[test_index] =clf.predict(X_test_selected)\n",
    "\n",
    "           # array = boruta_feature_selector.transform(X)\n",
    "\n",
    "          \n",
    "            for x in np.nditer(indexes):\n",
    "                parzial_features.append(features[x])\n",
    "\n",
    "        #fine ciclo for\n",
    "        \n",
    "    #calcolare media di sensitivity ecc. QUI\n",
    "  \n",
    "    \n",
    "X_filtered = boruta_feature_selector.transform(X)\n",
    "final_features = list()\n",
    "indexes = np.where(boruta_feature_selector.support_ == True)\n",
    "#for x in np.nditer(indexes):\n",
    " #   final_features.append(features[x])\n",
    "#print(final_features)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CAT.Fever          3 0.02\n",
      "CAT.Cough          0 0.0\n",
      "CAT.Dyspnea          8 0.05333333333333334\n",
      "CAT.IR          0 0.0\n",
      "CAT.Myalgias          0 0.0\n",
      "CAT.Other          0 0.0\n",
      "CAT.Syncope          0 0.0\n",
      "CAT.Asthenia          0 0.0\n",
      "CAT.Vomiting.Nausea          98 0.6533333333333333\n",
      "CAT.Diarrhea          13 0.08666666666666667\n",
      "CAT.Headache          0 0.0\n",
      "CAT.Pharingeal.pain          0 0.0\n",
      "INT.No.Symptoms          137 0.9133333333333333\n",
      "CAT.Pneumo.asthma          0 0.0\n",
      "CAT.Pneumo.BPCO          0 0.0\n",
      "CAT.Neoplasia.last.5.years          66 0.44\n",
      "CAT.Smoke          0 0.0\n",
      "CAT.Arterial.hypertension          0 0.0\n",
      "CAT.Cardiovascular.pathologies          20 0.13333333333333333\n",
      "CAT.Diabetes          76 0.5066666666666667\n",
      "CAT.Obesity          0 0.0\n",
      "CAT.Celebral.stroke          0 0.0\n",
      "INT.No.Comorbidities          144 0.96\n",
      "CAT.Sex          0 0.0\n",
      "INT.Age          150 1.0\n",
      "INT.Symptoms.No.days          149 0.9933333333333333\n",
      "INT.usa.radio.score.MAX          92 0.6133333333333333\n",
      "INT.radio.SCORE          149 0.9933333333333333\n",
      "NUM.GEO.extent.score          150 1.0\n",
      "NUM.OPC.extent.score          150 1.0\n",
      "INT.PaO2.PF          150 1.0\n",
      "INT.SpO2.in.FA          150 1.0\n",
      "INT.ALT          150 1.0\n",
      "INT.Platelets          150 1.0\n",
      "NUM.White.blood.cells          150 1.0\n",
      "NUM.Red.blood.cells          150 1.0\n",
      "NUM.Lymphocyte          150 1.0\n",
      "NUM.perc.Lymphocyte          150 1.0\n",
      "NUM.CRP          150 1.0\n",
      "NUM.Haemoglobin          150 1.0\n",
      "NUM.Haematocrit          150 1.0\n",
      "['CAT.Vomiting.Nausea', 'INT.No.Symptoms', 'INT.No.Comorbidities', 'INT.Age', 'INT.Symptoms.No.days', 'INT.usa.radio.score.MAX', 'INT.radio.SCORE', 'NUM.GEO.extent.score', 'NUM.OPC.extent.score', 'INT.PaO2.PF', 'INT.SpO2.in.FA', 'INT.ALT', 'INT.Platelets', 'NUM.White.blood.cells', 'NUM.Red.blood.cells', 'NUM.Lymphocyte', 'NUM.perc.Lymphocyte', 'NUM.CRP', 'NUM.Haemoglobin', 'NUM.Haematocrit']\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "for i in features:\n",
    "  c=parzial_features.count(i)\n",
    "  print(i,'        ', c, c/(nit*n_fold))\n",
    "  if (c>90):\n",
    "    final_features.append(i)\n",
    "print(final_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
